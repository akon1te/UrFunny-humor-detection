{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset import HumorDataset\n",
    "from metrics import metrics\n",
    "from pickle_loader import load_pickle\n",
    "\n",
    "from typing import Tuple, List, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Reggie/muppet-roberta-base-joke_detector\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=510)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10166it [01:42, 99.34it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = HumorDataset()\n",
    "predictions = []\n",
    "true_y = []\n",
    "for item in tqdm(dataset):\n",
    "    tokenized_text = tokenizer(item[1], '', truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    output = model(tokenized_text[\"input_ids\"].to(device))\n",
    "    \n",
    "    predictions.append(torch.softmax(output[\"logits\"][0], -1).tolist()[1])\n",
    "    true_y.append(item[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "for threshold in [0.2, 0.4, 0.6, 0.8]:\n",
    "    y_pred = []\n",
    "    for pred in predictions:\n",
    "        y_pred.append(1 if pred > threshold else 0)\n",
    "    curr_metrics = metrics(y_pred, true_y)\n",
    "    all_metrics.append((threshold, curr_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2, (0.5248868778280543, 0.5324442164657605, 0.40842022427700175)),\n",
       " (0.4, (0.5251819791461735, 0.5366342301087579, 0.36887664764902617)),\n",
       " (0.6, (0.5241983080857762, 0.5390724269377383, 0.3338579578988786)),\n",
       " (0.8, (0.5240999409797363, 0.5456238361266295, 0.28821562069643913))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
