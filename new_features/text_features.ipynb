{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaModel \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset import HumorDataset\n",
    "\n",
    "from pickle_loader import load_pickle\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(device)\n",
    "model_name = 'Reggie/muppet-roberta-base-joke_detector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HumorDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " \"the mathematics of quantum mechanics very accurately describes how our universe works. and it tells us our reality is continually branching into different possibilities just like a coral. it's a weird thing for us humans to wrap our minds around since we only ever get to experience one possibility. this quantum weirdness was first described by erwin and his cat. the cat likes this version better\",\n",
       " WindowsPath('../data/urfunny2_video/1.mp4'),\n",
       " WindowsPath('../data/urfunny2_audio/1.mp3'),\n",
       " 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_output_embeddings() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mget_output_embeddings())\n\u001b[0;32m      4\u001b[0m input_seq \u001b[39m=\u001b[39m tokenizer(sample[\u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mget_output_embeddings(input_seq[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device))\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(output)\n\u001b[0;32m      7\u001b[0m prediction \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(output[\u001b[39m\"\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n",
      "\u001b[1;31mTypeError\u001b[0m: get_output_embeddings() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(model_name, model_max_length=510)\n",
    "model = RobertaModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "input_seq = tokenizer(sample[1], '', truncation=True, return_tensors=\"pt\")\n",
    "output = model(input_seq[\"input_ids\"].to(device))\n",
    "prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "print(prediction)\n",
    "pred_out = 1 if prediction[0] < prediction[1] else 0\n",
    "print('This is a joke') if pred_out == 1 else print('This is not a joke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
